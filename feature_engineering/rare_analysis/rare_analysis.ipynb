{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiV_OVyOy8vL"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow_recommenders as tfrs"
      ],
      "metadata": {
        "id": "d873gYbD0CGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import sys\n",
        "import csv\n",
        "import gzip\n",
        "import copy\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "from tabulate import tabulate"
      ],
      "metadata": {
        "id": "8oRrlXZI0ETP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_value = 42  # seed for reproducibility\n",
        "random.seed(seed_value)"
      ],
      "metadata": {
        "id": "tIqMLfCl0K2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "HO3hrqUawL05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mtzzM19O0ZKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('/content/drive/MyDrive/ctr/code/model')"
      ],
      "metadata": {
        "id": "l_8Fpg8C9LZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dcn\n",
        "import run_models"
      ],
      "metadata": {
        "id": "DEaL_7Vy9YD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_PATH = '/content/drive/MyDrive/ctr/avazu/processed/train/train.csv'\n",
        "train = pd.read_csv(FILE_PATH)"
      ],
      "metadata": {
        "id": "WkfHADIhFAEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE = 1000\n",
        "sample = train.head(SAMPLE_SIZE)"
      ],
      "metadata": {
        "id": "qoRZT8r55W4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_dimensional_features = {\n",
        "    'site' : ['site_id', 'site_domain'],\n",
        "    'device' : ['device_model'],\n",
        "    'app' : ['app_id', 'app_domain'],\n",
        "    'categorical' : ['C14', 'C17', 'C19', 'C20']\n",
        "}"
      ],
      "metadata": {
        "id": "LqxLQvaH5sp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Rare Analysis</h2>\n",
        "1. Frequency Top N개의 Category 에 대한 분석 = Top Num <br>\n",
        "2. Frequency가 기준 이상인 Category에 대한 분석 = Over Threshold"
      ],
      "metadata": {
        "id": "SLTd-AC27-ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using only Top-10 Fetures"
      ],
      "metadata": {
        "id": "xaffovQh6NrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_analysis(data, multi_dimensional_features, verbose=False):\n",
        "    # TOP_NUM_LIST = list(range(10,60,10))\n",
        "    # THRESHOLD_LIST = [10, 100, 200, 500, 1000]\n",
        "\n",
        "    key_pair_list = [(10, 1000), (25, 500), (50, 10)]\n",
        "\n",
        "    TOTAL_IMP = len(data)\n",
        "    voca = {}\n",
        "    feature_analysis = pd.DataFrame(\n",
        "        columns = [\n",
        "            'Feature Cate',\n",
        "            'Feature Name',\n",
        "            'Top-Num',\n",
        "            'Threshold',\n",
        "            '#Cate',\n",
        "            'Top-Num #Cate Ratio',\n",
        "            'Over-Thr. #Cate Ratio',\n",
        "            'Over-Thr. #Cate Count',\n",
        "            'Top-Num #Imp Ratio',\n",
        "            'Top-Num #Imp Count',\n",
        "            'Over-Thr. #Imp Ratio',\n",
        "            'Over-Thr. #Imp Count'\n",
        "        ]\n",
        "    )\n",
        "    for TOP_NUM, THRESHOLD in key_pair_list:\n",
        "        print(\"Top Num: {}\".format(TOP_NUM))\n",
        "        print(\"Threshold : {}\".format(THRESHOLD))\n",
        "        key_pair = (TOP_NUM, THRESHOLD)\n",
        "        voca[key_pair] = {}\n",
        "        for f_cate, f_list in multi_dimensional_features.items():\n",
        "            for feature in f_list:\n",
        "                counts = data.value_counts(feature, ascending=False)\n",
        "                over_threshold = counts[counts > THRESHOLD]\n",
        "\n",
        "                num_cate, over_cate = len(counts), len(over_threshold)\n",
        "\n",
        "                top_num_cate = list(counts.head(TOP_NUM).index)\n",
        "                over_threshold_cate = list(over_threshold.index)\n",
        "\n",
        "                voca[key_pair][feature] = {\n",
        "                    'top_num' : top_num_cate,\n",
        "                    'over_threshold' : over_threshold_cate\n",
        "                }\n",
        "\n",
        "                top_num_imp_count = np.sum(data[feature].apply(lambda x : x in top_num_cate))\n",
        "                over_threshold_imp_count = np.sum(data[feature].apply(lambda x : x in over_threshold_cate))\n",
        "\n",
        "                top_num_imp_ratio = top_num_imp_count / TOTAL_IMP * 100\n",
        "                over_threshold_imp_ratio = over_threshold_imp_count / TOTAL_IMP * 100\n",
        "\n",
        "                feature_analysis.loc[len(feature_analysis)] = {\n",
        "                    'Feature Cate' : f_cate,\n",
        "                    'Feature Name' : feature,\n",
        "                    'Top-Num' : TOP_NUM,\n",
        "                    'Threshold' : THRESHOLD,\n",
        "                    '#Cate' : num_cate,\n",
        "                    'Top-Num #Cate Ratio' : TOP_NUM / num_cate * 100,\n",
        "                    'Over-Thr. #Cate Ratio' : over_cate / num_cate * 100,\n",
        "                    'Over-Thr. #Cate Count' : over_cate,\n",
        "                    'Top-Num #Imp Ratio' : top_num_imp_ratio,\n",
        "                    'Top-Num #Imp Count' : top_num_imp_count,\n",
        "                    'Over-Thr. #Imp Ratio' : over_threshold_imp_ratio,\n",
        "                    'Over-Thr. #Imp Count' : over_threshold_imp_count\n",
        "                }\n",
        "    return feature_analysis, voca"
      ],
      "metadata": {
        "id": "H2TdTjKxuH78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = train\n",
        "feature_analysis, total_voca = get_feature_analysis(data, multi_dimensional_features)"
      ],
      "metadata": {
        "id": "nqvH_QbUyqP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "low_threshold = feature_analysis[(feature_analysis['Top-Num'] == 100) & (feature_analysis['Threshold'] == 10)]\n",
        "mid_threshold = feature_analysis[(feature_analysis['Top-Num'] == 50) & (feature_analysis['Threshold'] == 500)]\n",
        "high_threshold = feature_analysis[(feature_analysis['Top-Num'] == 10) & (feature_analysis['Threshold'] == 1000)]"
      ],
      "metadata": {
        "id": "MUIPvsuAxE6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Rare Count 집계</h2>"
      ],
      "metadata": {
        "id": "pJYB8Z9u72KW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE = 10000\n",
        "data = train.head(SAMPLE_SIZE)\n",
        "key_pair_list = [(10, 1000), (25, 500), (50, 10)]"
      ],
      "metadata": {
        "id": "EKAbBiu-CLZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rare_count_dict = {}"
      ],
      "metadata": {
        "id": "LGGGfdM5CfBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key_pair in key_pair_list:\n",
        "    rare_count_dict[key_pair] = {}\n",
        "    voca_dict = total_voca[key_pair]\n",
        "    rare_count_dict[key_pair]['Top Num Rare Count'] = np.array([0] * len(data))\n",
        "    rare_count_dict[key_pair]['Over Threshold Rare Count'] = np.array([0] * len(data))\n",
        "    total_f_num = 0\n",
        "    for f_cate, f_list in multi_dimensional_features.items():\n",
        "        for feature in f_list:\n",
        "            total_f_num += 1\n",
        "            top_num_voca, over_threshold_voca = voca_dict[feature]['top_num'], voca_dict[feature]['over_threshold']\n",
        "            top_num_rare = data[feature].apply(lambda x: 0 if x in top_num_voca else 1)\n",
        "            over_threshold_rare = data[feature].apply(lambda x: 0 if x in over_threshold_voca else 1)\n",
        "            rare_count_dict[key_pair]['Top Num Rare Count'] += top_num_rare\n",
        "            rare_count_dict[key_pair]['Over Threshold Rare Count'] += over_threshold_rare"
      ],
      "metadata": {
        "id": "rdjhj5Nc70_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_idx_list_total = []\n",
        "TOP_NUM_LIST_TOTAL = []\n",
        "THRSHOLD_LIST_TOTAL = []\n",
        "TOP_NUM_RARE_COUNT_TOTAL = []\n",
        "OVER_THRESHOLD_COUNT_TOTAL = []\n",
        "\n",
        "user_list = list(data.index)\n",
        "for (TOP_NUM, THRESHOLD), count_dict in rare_count_dict.items():\n",
        "    user_idx_list_total += user_list\n",
        "\n",
        "    TOP_NUM_LIST_TOTAL += [TOP_NUM] * len(data)\n",
        "    THRSHOLD_LIST_TOTAL += [THRESHOLD] * len(data)\n",
        "\n",
        "    TOP_NUM_RARE_COUNT_TOTAL += list(count_dict['Top Num Rare Count'])\n",
        "    OVER_THRESHOLD_COUNT_TOTAL += list(count_dict['Over Threshold Rare Count'])\n",
        "\n",
        "rare_count_df = pd.DataFrame(\n",
        "    data = {\n",
        "        'user_idx' : user_idx_list_total,\n",
        "        'Top Num' : TOP_NUM_LIST_TOTAL,\n",
        "        'Threshold' : THRSHOLD_LIST_TOTAL,\n",
        "        'Top Num Rare Count' : TOP_NUM_RARE_COUNT_TOTAL,\n",
        "        'Over Threshold Rare Count' : OVER_THRESHOLD_COUNT_TOTAL\n",
        "        }\n",
        ")"
      ],
      "metadata": {
        "id": "CyCkgQ7oEP7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rare_cnt_low_threshold = rare_count_df[(rare_count_df['Top Num'] == 50) & (rare_count_df['Threshold'] == 10)]\n",
        "rare_cnt_mid_threshold = rare_count_df[(rare_count_df['Top Num'] == 25) & (rare_count_df['Threshold'] == 500)]\n",
        "rare_cnt_high_threshold = rare_count_df[(rare_count_df['Top Num'] == 10) & (rare_count_df['Threshold'] == 1000)]"
      ],
      "metadata": {
        "id": "HKBGBIDZGWGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rare_count_df.to_csv('/content/drive/MyDrive/ctr/data/rare_count_df.csv', index=False)"
      ],
      "metadata": {
        "id": "fun_c4dbH9Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(rare_cnt_low_threshold.value_counts('Top Num Rare Count', ascending=False, normalize=True) * 100).apply(\"{:.2f}%\".format)"
      ],
      "metadata": {
        "id": "0_mTJG4lG0w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_cnt = (rare_cnt_low_threshold.value_counts('Top Num Rare Count', ascending=False, normalize=True) * 100).sort_index(ascending=True)"
      ],
      "metadata": {
        "id": "BifVkElXkzQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_cnt.plot(kind='bar')"
      ],
      "metadata": {
        "id": "uqZXuxbxlAnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(rare_cnt_low_threshold.value_counts('Over Threshold Rare Count', ascending=False, normalize=True) * 100).apply(\"{:.2f}%\".format)"
      ],
      "metadata": {
        "id": "rrA9M098HKYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(rare_cnt_mid_threshold.value_counts('Top Num Rare Count', ascending=False, normalize=True) * 100).apply(\"{:.2f}%\".format)"
      ],
      "metadata": {
        "id": "SjqQpNCuHXYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(rare_cnt_mid_threshold.value_counts('Over Threshold Rare Count', ascending=False, normalize=True) * 100).apply(\"{:.2f}%\".format)"
      ],
      "metadata": {
        "id": "QxwTl0_0HXSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(rare_cnt_high_threshold.value_counts('Top Num Rare Count', ascending=False, normalize=True) * 100).apply(\"{:.2f}%\".format)"
      ],
      "metadata": {
        "id": "K_A1HJ60HXKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(rare_cnt_high_threshold.value_counts('Over Threshold Rare Count', ascending=False, normalize=True) * 100).apply(\"{:.2f}%\".format)"
      ],
      "metadata": {
        "id": "-V5Fk8OIHW-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1fkxEJyRHkIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXU1mDwrHkDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NtatOCHTHj7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = np.array([0] * len(data))"
      ],
      "metadata": {
        "id": "XlUYicaeD3n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_num_rare = data[feature].apply(lambda x: 0 if x in top_num_voca else 1)"
      ],
      "metadata": {
        "id": "jAqnHRzbD6RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_f_num"
      ],
      "metadata": {
        "id": "Rf6wkZbkAuIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(data.value_counts('top num rare count', ascending = False, normalize=True) * 100).apply('{:.2f}%'.format)"
      ],
      "metadata": {
        "id": "422_Kf8D_1Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(data.value_counts('over threshold rare count', ascending = False, normalize=True) * 100).apply('{:.2f}%'.format)"
      ],
      "metadata": {
        "id": "oiAIZew-Aqai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(data['rare count'])"
      ],
      "metadata": {
        "id": "7h-hOfY270wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9rGIrU4b_Db7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count_analysis(TOP_NUM, feature, data, verbose=False):\n",
        "    total_proportion = data.value_counts(feature, ascending=False, normalize=True) * 100\n",
        "    total_counts = data.value_counts(feature, ascending=False)\n",
        "    total_f_num = len(total_counts)\n",
        "\n",
        "    proportion = total_proportion.head(TOP_NUM).apply('{:.2f}'.format)\n",
        "    counts = total_counts.head(TOP_NUM)\n",
        "    count_values = pd.DataFrame({\n",
        "        'proportion' : proportion,\n",
        "        'count' : counts\n",
        "    })\n",
        "\n",
        "    if verbose:\n",
        "        print(\"총 Category 개수 : {}\".format(total_f_num))\n",
        "        print(\"Top Feture의 비율 : {:.2f}%\".format(10 / total_f_num * 100))\n",
        "\n",
        "        print(\"마지막 Category의 비율 : {:.2f}\".format(total_proportion.head(TOP_NUM).iloc[-1]))\n",
        "        print(\"마지막 Category의 Count : {}\".format(total_counts.head(TOP_NUM).iloc[-1]))\n",
        "        print()\n",
        "\n",
        "    return list(count_values.index)"
      ],
      "metadata": {
        "id": "PyFWjgzg6oA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_voca_top(TOP_NUM, data, verbose=False):\n",
        "    voca_top = {}\n",
        "    for f_cate, f_list in multi_dimensional_features.items():\n",
        "        for feature in f_list:\n",
        "            voca_top[feature] = get_count_analysis(TOP_NUM, feature, data)\n",
        "    return voca_top"
      ],
      "metadata": {
        "id": "r85mzCLiDlRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_NUM = 10\n",
        "data = train\n",
        "voca_top = get_voca_top(TOP_NUM, data, verbose=False)"
      ],
      "metadata": {
        "id": "BnwnL7miDUvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count_analysis_threshold(THRESHOLD, feature, data, verbose=False):\n",
        "    counts = data.value_counts(feature, ascending=False)\n",
        "    over_threshold = counts[counts > THRESHOLD]\n",
        "\n",
        "    num_cate, over_cate = len(counts), len(over_threshold)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"총 Category 개수 : {}개\".format(num_cate))\n",
        "        print(\"기준 이상의 Category 개수 : {}개\".format(over_cate))\n",
        "        print(\"생략 되는 Category 개수 : {}개\".format(num_cate - over_cate))\n",
        "        print(\"기준 이상의 Category 퍼센트 : {:.2f}%\".format(over_cate / num_cate * 100))\n",
        "    return list(over_threshold.index)"
      ],
      "metadata": {
        "id": "YuCoilum9SDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_voca(THRESHOLD, data, verbose=False):\n",
        "    voca = {}\n",
        "    for f_cate, f_list in multi_dimensional_features.items():\n",
        "        for feature in f_list:\n",
        "            voca[feature] = get_count_analysis_threshold(THRESHOLD, feature, data)\n",
        "    return voca"
      ],
      "metadata": {
        "id": "QtfDfjuIEsgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 100\n",
        "data = train\n",
        "voca = get_voca(THRESHOLD, data)"
      ],
      "metadata": {
        "id": "LzjP74lC8uDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# with open('/content/drive/MyDrive/ctr/data/voca_top.p', 'wb') as f:\n",
        "#     pickle.dump(voca_top, f)\n",
        "# with open('/content/drive/MyDrive/ctr/data/voca.p', 'wb') as f:\n",
        "#     pickle.dump(voca, f)"
      ],
      "metadata": {
        "id": "5EPPW3PVE60o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KZxFMixAFEvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_qy_4cfFsH2N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}